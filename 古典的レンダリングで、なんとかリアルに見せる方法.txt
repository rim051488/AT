お悩み
blenderでノーマルマップありのメッシュ作って
DxLibで読み込んだけど、ノーマルマップが
反映されない
(metasequoiaのデータだとノーマルが反映)

メタセコの場合、頂点情報とインデックスくらい
しか出力されません。

なぜ、法線が載ってるのか。メタセコは
情報が少ないってはじめっからわかってるので
法線はMV1に変換するときorDxLibに読み込まれる時に計算される。
mqoファイル自体がノーマルマップへのパスを持ってる場合
接ベクトルと従法線ベクトルをロード時に再計算する。
このため、法線マップさえ入ってれば勝手に反映される。

ところがblenderに関してはその辺の責任は出力者に
任せられる。
つまり、法線マップが入ってても、接ベクトルや従法線ベクトル
を再計算してくれない。やるなら、blenderのエクスポートで
やるしかない。

たとえばFBX出力なら、「ジオメトリ」の「タンジェント空間」
にチェックを入れましょう。

PBRについて
古典的レンダリングが
・ディフューズ(内積で計算可能)
・スペキュラー(内積と指数で計算可能)
・アンビエント(maxか加算で計算可能)
で構成されてました。これを計算式を変えて
・ラフネス(F項＋D項＋G項)
・メタリック(材質の色が出るかどうか)
・アルベド(元の色)
にしたものがPBRです。そもそも計算式がややこしい。
あと、PBRって呼ばれてるものがリアルに見えるのは
計算式のおかげばかりではない…。

それは何か、IBL(ImageBasedLighting)である。
Lightingなんて言うとりますけれども、結局は周囲が
写りこむかどうかの話です。
周りを反射すると、より「それっぽくなる」
で、PBRを使ってるレンダラの場合はこの周りが映り込むのを
表現するために「キューブマップ」というのを使っている。

で、ラフネス値が高いと、周囲の光が拡散して、ぼやけて見える

普通に考えると「ガウスぼかし」を使ってぼけさせるが
これは滅茶苦茶思い←何故かというと、１ピクセルをぼかすために
周囲ｒ＊ｒぶんのピクセル情報が必要になるから。
仮に10ピクセルぼかそうとすると100ピクセルの参照が
必要になる→これは重いッ！

もともとモアレやエイリアス防止のために
「ミップマップ」というものが使われてきた。
ミップマップというのは、あらかじめ半分半分の大きさの
テクスチャを用意しているものである。

ゲームではこの「ミップマップ」とバイリニア補間を用いて
ぼかしを行っている。どのミップマップを使うかという話な
だけなので、参照ピクセル回数は１回でいい。これでボケてる。

ただし、PBRは難しいし、環境マップは通常、
動的にキューブマップを作成して(ミップマップも同時製造)して
それを用いてリアル感出してる。

ただしPBRの計算式は難しいし、キューブマップを動的に
作るのも大変。

なんとか、diffuse,specular,ambient & normalmapあとはラフネスマップ
とかでなんとかそれっぽくならないのか？

まず、IBLに関してですが、どうせボケると考えて
どこでも通用しそうな背景で「スフィアマップ」を用意しておく

PBRはなぜリアルなのか
①フレネル(視線と直交するほど反射する)
	これをなんちゃって再現する
	1-saturate(-V・N)
	これを反射率に反映させる
②PBRの肝としてはエネルギー保存の法則があるので
	ラフネス値をrghとすると
	col=lerp(specular,diffuse,rgh);
	で、それっぽくなる。当然暗くなるので、そこは調整
③反射率が高い部分は周りを映り込ますんですが、
	スフィアマップでごまかす







